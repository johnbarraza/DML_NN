{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5f7ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e352602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[36m\u001b[1m     Project\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Project.toml`\n",
      "\u001b[36m\u001b[1m    Manifest\u001b[22m\u001b[39m No packages added to or removed from `C:\\Users\\user2\\.julia\\environments\\v1.12\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add([\"CSV\", \"DataFrames\", \"StatsModels\", \"GLM\", \"Random\", \"Downloads\", \"CategoricalArrays\", \"Statistics\", \"PrettyTables\"])\n",
    "Pkg.add(\"MLJ\")\n",
    "Pkg.add(\"MLJScikitLearnInterface\") # Para OLS, Lasso, RF\n",
    "Pkg.add(\"MLJFlux\") # Para Redes Neuronales\n",
    "Pkg.add(\"Flux\")\n",
    "Pkg.add(\"Crayons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717b3a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, StatsModels, GLM, Random, Downloads, CategoricalArrays, Statistics, PrettyTables\n",
    "using MLJ, MLJScikitLearnInterface, MLJFlux, Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9d1966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:/Users/user2/Documents/GitHub/DML_NN/julia/output\\\\comparison_table.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_dir = \"C:/Users/user2/Documents/GitHub/DML_NN/julia/output\"\n",
    "mkpath(output_dir)\n",
    "output_path = joinpath(output_dir, \"comparison_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e69b7d",
   "metadata": {},
   "source": [
    "# carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb71190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23-element Vector{String}:\n",
       " \"abdt\"\n",
       " \"tg\"\n",
       " \"inuidur1\"\n",
       " \"inuidur2\"\n",
       " \"female\"\n",
       " \"black\"\n",
       " \"hispanic\"\n",
       " \"othrace\"\n",
       " \"dep\"\n",
       " \"q1\"\n",
       " ⋮\n",
       " \"q6\"\n",
       " \"recall\"\n",
       " \"agelt35\"\n",
       " \"agegt54\"\n",
       " \"durable\"\n",
       " \"nondurable\"\n",
       " \"lusd\"\n",
       " \"husd\"\n",
       " \"muld\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Limpieza de datos\n",
    "nombres = [\n",
    "    \"abdt\", \"tg\", \"inuidur1\", \"inuidur2\", \"female\", \"black\", \"hispanic\", \n",
    "    \"othrace\", \"dep\", \"q1\", \"q2\", \"q3\", \"q4\", \"q5\", \"q6\", \"recall\", \n",
    "    \"agelt35\", \"agegt54\", \"durable\", \"nondurable\", \"lusd\", \"husd\", \"muld\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab10957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/CausalAIBook/MetricsMLNotebooks/main/data/penn_jae.dat\"\n",
    "file_path = \"penn_jae.dat\"  ## C:\\Users\\user2\\Documents\\GitHub\\DML_NN\\input\\penn_jae.dat\n",
    "if !isfile(file_path)\n",
    "    Downloads.download(url, file_path)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09dbd932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>13913×23 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">13888 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">abdt</th><th style = \"text-align: left;\">tg</th><th style = \"text-align: left;\">inuidur1</th><th style = \"text-align: left;\">inuidur2</th><th style = \"text-align: left;\">female</th><th style = \"text-align: left;\">black</th><th style = \"text-align: left;\">hispanic</th><th style = \"text-align: left;\">othrace</th><th style = \"text-align: left;\">dep</th><th style = \"text-align: left;\">q1</th><th style = \"text-align: left;\">q2</th><th style = \"text-align: left;\">q3</th><th style = \"text-align: left;\">q4</th><th style = \"text-align: left;\">q5</th><th style = \"text-align: left;\">q6</th><th style = \"text-align: left;\">recall</th><th style = \"text-align: left;\">agelt35</th><th style = \"text-align: left;\">agegt54</th><th style = \"text-align: left;\">durable</th><th style = \"text-align: left;\">nondurable</th><th style = \"text-align: left;\">lusd</th><th style = \"text-align: left;\">husd</th><th style = \"text-align: left;\">muld</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">10824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">10635</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">10551</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">10824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">10747</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">10544</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">7</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">10845</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">10670</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">10768</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">10754</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">10712</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">10607</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">10831</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13902</td><td style = \"text-align: right;\">10705</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">14</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13903</td><td style = \"text-align: right;\">10768</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13904</td><td style = \"text-align: right;\">10747</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13905</td><td style = \"text-align: right;\">10628</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13906</td><td style = \"text-align: right;\">10523</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13907</td><td style = \"text-align: right;\">10558</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13908</td><td style = \"text-align: right;\">10621</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13909</td><td style = \"text-align: right;\">10831</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13910</td><td style = \"text-align: right;\">10677</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13911</td><td style = \"text-align: right;\">10817</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13912</td><td style = \"text-align: right;\">10691</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13913</td><td style = \"text-align: right;\">10677</td><td style = \"text-align: right;\">5</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">25</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& abdt & tg & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & q1 & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10824 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t2 & 10635 & 2 & 7 & 3 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t3 & 10551 & 5 & 18 & 6 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t4 & 10824 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t5 & 10747 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t6 & 10544 & 6 & 7 & 7 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t7 & 10845 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t8 & 10670 & 3 & 3 & 3 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t9 & 10768 & 3 & 28 & 11 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t10 & 10754 & 2 & 20 & 20 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t11 & 10712 & 3 & 6 & 6 & 0 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t12 & 10607 & 4 & 9 & 9 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t13 & 10831 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t14 & 10845 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t15 & 10831 & 0 & 9 & 9 & 1 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t16 & 10551 & 3 & 27 & 27 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t17 & 10859 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t18 & 10740 & 1 & 15 & 15 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t19 & 10537 & 1 & 1 & 1 & 0 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t20 & 10663 & 6 & 26 & 26 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t21 & 10656 & 5 & 30 & 9 & 0 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t22 & 10628 & 2 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t23 & 10516 & 0 & 15 & 15 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t24 & 10803 & 2 & 3 & 3 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m13913×23 DataFrame\u001b[0m\n",
       "\u001b[1m   Row \u001b[0m│\u001b[1m abdt  \u001b[0m\u001b[1m tg    \u001b[0m\u001b[1m inuidur1 \u001b[0m\u001b[1m inuidur2 \u001b[0m\u001b[1m female \u001b[0m\u001b[1m black \u001b[0m\u001b[1m hispanic \u001b[0m\u001b[1m othrace \u001b[0m\u001b[1m d\u001b[0m ⋯\n",
       "       │\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64   \u001b[0m\u001b[90m I\u001b[0m ⋯\n",
       "───────┼────────────────────────────────────────────────────────────────────────\n",
       "     1 │ 10824      0        18        18       0      0         0        0    ⋯\n",
       "     2 │ 10635      2         7         3       0      0         0        0\n",
       "     3 │ 10551      5        18         6       1      0         0        0\n",
       "     4 │ 10824      0         1         1       0      0         0        0\n",
       "     5 │ 10747      0        27        27       0      0         0        0    ⋯\n",
       "     6 │ 10544      6         7         7       0      0         0        0\n",
       "     7 │ 10845      1         1         1       0      0         0        0\n",
       "     8 │ 10670      3         3         3       1      0         0        0\n",
       "   ⋮   │   ⋮      ⋮       ⋮         ⋮        ⋮       ⋮       ⋮         ⋮       ⋱\n",
       " 13907 │ 10558      0         9         9       0      0         0        0    ⋯\n",
       " 13908 │ 10621      1         1         1       0      0         0        0\n",
       " 13909 │ 10831      5        27        27       0      0         0        0\n",
       " 13910 │ 10677      2         4         4       1      0         0        0\n",
       " 13911 │ 10817      4         4         4       0      0         0        0    ⋯\n",
       " 13912 │ 10691      0        27        27       0      0         0        0\n",
       " 13913 │ 10677      5        25        25       0      0         0        0\n",
       "\u001b[36m                                               15 columns and 13898 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = CSV.read(file_path, DataFrame, skipto=2, header=nombres, delim=' ', ignorerepeated=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a683c",
   "metadata": {},
   "source": [
    "## limpiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "699f5b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5099×23 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">5074 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">abdt</th><th style = \"text-align: left;\">tg</th><th style = \"text-align: left;\">inuidur1</th><th style = \"text-align: left;\">inuidur2</th><th style = \"text-align: left;\">female</th><th style = \"text-align: left;\">black</th><th style = \"text-align: left;\">hispanic</th><th style = \"text-align: left;\">othrace</th><th style = \"text-align: left;\">dep</th><th style = \"text-align: left;\">q1</th><th style = \"text-align: left;\">q2</th><th style = \"text-align: left;\">q3</th><th style = \"text-align: left;\">q4</th><th style = \"text-align: left;\">q5</th><th style = \"text-align: left;\">q6</th><th style = \"text-align: left;\">recall</th><th style = \"text-align: left;\">agelt35</th><th style = \"text-align: left;\">agegt54</th><th style = \"text-align: left;\">durable</th><th style = \"text-align: left;\">nondurable</th><th style = \"text-align: left;\">lusd</th><th style = \"text-align: left;\">husd</th><th style = \"text-align: left;\">muld</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">10824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">10824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">10747</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">10607</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">10831</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">10845</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">10831</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">10859</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">10516</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">10663</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">10747</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">10551</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">10768</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5088</td><td style = \"text-align: right;\">10691</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5089</td><td style = \"text-align: right;\">10796</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5090</td><td style = \"text-align: right;\">10635</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5091</td><td style = \"text-align: right;\">10859</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5092</td><td style = \"text-align: right;\">10796</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5093</td><td style = \"text-align: right;\">10740</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5094</td><td style = \"text-align: right;\">10845</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5095</td><td style = \"text-align: right;\">10628</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5096</td><td style = \"text-align: right;\">10523</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5097</td><td style = \"text-align: right;\">10558</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5098</td><td style = \"text-align: right;\">10817</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5099</td><td style = \"text-align: right;\">10691</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& abdt & tg & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & q1 & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10824 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t2 & 10824 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t3 & 10747 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t4 & 10607 & 4 & 9 & 9 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t5 & 10831 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t6 & 10845 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t7 & 10831 & 0 & 9 & 9 & 1 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t8 & 10859 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t9 & 10516 & 0 & 15 & 15 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t10 & 10663 & 0 & 28 & 11 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t11 & 10747 & 0 & 12 & 12 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t12 & 10551 & 4 & 22 & 22 & 1 & 0 & 1 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t13 & 10768 & 0 & 18 & 18 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t14 & 10537 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t15 & 10600 & 4 & 7 & 7 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t16 & 10866 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t17 & 10572 & 0 & 14 & 14 & 0 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t18 & 10663 & 0 & 5 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t19 & 10789 & 0 & 9 & 9 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t20 & 10768 & 0 & 3 & 3 & 0 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t21 & 10649 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t22 & 10670 & 4 & 27 & 27 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t23 & 10796 & 0 & 10 & 10 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t24 & 10558 & 0 & 25 & 25 & 0 & 0 & 1 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5099×23 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m abdt  \u001b[0m\u001b[1m tg    \u001b[0m\u001b[1m inuidur1 \u001b[0m\u001b[1m inuidur2 \u001b[0m\u001b[1m female \u001b[0m\u001b[1m black \u001b[0m\u001b[1m hispanic \u001b[0m\u001b[1m othrace \u001b[0m\u001b[1m de\u001b[0m ⋯\n",
       "      │\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64   \u001b[0m\u001b[90m In\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 10824      0        18        18       0      0         0        0     ⋯\n",
       "    2 │ 10824      0         1         1       0      0         0        0\n",
       "    3 │ 10747      0        27        27       0      0         0        0\n",
       "    4 │ 10607      4         9         9       0      0         0        0\n",
       "    5 │ 10831      0        27        27       0      0         0        0     ⋯\n",
       "    6 │ 10845      0        27        27       1      0         0        0\n",
       "    7 │ 10831      0         9         9       1      0         0        0\n",
       "    8 │ 10859      0        27        27       1      0         0        0\n",
       "  ⋮   │   ⋮      ⋮       ⋮         ⋮        ⋮       ⋮       ⋮         ⋮        ⋱\n",
       " 5093 │ 10740      4        13        13       1      1         0        0     ⋯\n",
       " 5094 │ 10845      0         6         6       1      0         0        1\n",
       " 5095 │ 10628      4        10        10       0      0         1        0\n",
       " 5096 │ 10523      4         4         4       0      0         1        0\n",
       " 5097 │ 10558      0         9         9       0      0         0        0     ⋯\n",
       " 5098 │ 10817      4         4         4       0      0         0        0\n",
       " 5099 │ 10691      0        27        27       0      0         0        0\n",
       "\u001b[36m                                                15 columns and 5084 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cleaned = filter(row -> row.tg == 0 || row.tg == 4, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf95de20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>5099×25 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">5074 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">abdt</th><th style = \"text-align: left;\">tg</th><th style = \"text-align: left;\">inuidur1</th><th style = \"text-align: left;\">inuidur2</th><th style = \"text-align: left;\">female</th><th style = \"text-align: left;\">black</th><th style = \"text-align: left;\">hispanic</th><th style = \"text-align: left;\">othrace</th><th style = \"text-align: left;\">dep</th><th style = \"text-align: left;\">q1</th><th style = \"text-align: left;\">q2</th><th style = \"text-align: left;\">q3</th><th style = \"text-align: left;\">q4</th><th style = \"text-align: left;\">q5</th><th style = \"text-align: left;\">q6</th><th style = \"text-align: left;\">recall</th><th style = \"text-align: left;\">agelt35</th><th style = \"text-align: left;\">agegt54</th><th style = \"text-align: left;\">durable</th><th style = \"text-align: left;\">nondurable</th><th style = \"text-align: left;\">lusd</th><th style = \"text-align: left;\">husd</th><th style = \"text-align: left;\">muld</th><th style = \"text-align: left;\">T4</th><th style = \"text-align: left;\">y</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Bool\" style = \"text-align: left;\">Bool</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">10824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.89037</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">10824</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">10747</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.29584</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">10607</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.19722</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">10831</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.29584</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">10845</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.29584</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">10831</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.19722</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">10859</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.29584</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">10516</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.70805</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">10663</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">28</td><td style = \"text-align: right;\">11</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.3322</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">10747</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">12</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.48491</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">10551</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">22</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">3.09104</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">10768</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">18</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.89037</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5088</td><td style = \"text-align: right;\">10691</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.29584</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5089</td><td style = \"text-align: right;\">10796</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">15</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.70805</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5090</td><td style = \"text-align: right;\">10635</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">20</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.99573</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5091</td><td style = \"text-align: right;\">10859</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">0.0</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5092</td><td style = \"text-align: right;\">10796</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">23</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.13549</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5093</td><td style = \"text-align: right;\">10740</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">13</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.56495</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5094</td><td style = \"text-align: right;\">10845</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">6</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">1.79176</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5095</td><td style = \"text-align: right;\">10628</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">10</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">2.30259</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5096</td><td style = \"text-align: right;\">10523</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">1.38629</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5097</td><td style = \"text-align: right;\">10558</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">9</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">2.19722</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5098</td><td style = \"text-align: right;\">10817</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">4</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">true</td><td style = \"text-align: right;\">1.38629</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5099</td><td style = \"text-align: right;\">10691</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">27</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">0</td><td style = \"text-align: right;\">false</td><td style = \"text-align: right;\">3.29584</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccccc}\n",
       "\t& abdt & tg & inuidur1 & inuidur2 & female & black & hispanic & othrace & dep & q1 & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 10824 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t2 & 10824 & 0 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t3 & 10747 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t4 & 10607 & 4 & 9 & 9 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t5 & 10831 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t6 & 10845 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t7 & 10831 & 0 & 9 & 9 & 1 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t8 & 10859 & 0 & 27 & 27 & 1 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t9 & 10516 & 0 & 15 & 15 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t10 & 10663 & 0 & 28 & 11 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t11 & 10747 & 0 & 12 & 12 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t12 & 10551 & 4 & 22 & 22 & 1 & 0 & 1 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t13 & 10768 & 0 & 18 & 18 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t14 & 10537 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t15 & 10600 & 4 & 7 & 7 & 1 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t16 & 10866 & 0 & 18 & 18 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t17 & 10572 & 0 & 14 & 14 & 0 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t18 & 10663 & 0 & 5 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t19 & 10789 & 0 & 9 & 9 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t20 & 10768 & 0 & 3 & 3 & 0 & 1 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t21 & 10649 & 0 & 27 & 27 & 0 & 0 & 0 & 0 & 1 & 0 & $\\dots$ \\\\\n",
       "\t22 & 10670 & 4 & 27 & 27 & 1 & 0 & 0 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t23 & 10796 & 0 & 10 & 10 & 0 & 0 & 0 & 0 & 0 & 0 & $\\dots$ \\\\\n",
       "\t24 & 10558 & 0 & 25 & 25 & 0 & 0 & 1 & 0 & 2 & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m5099×25 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m abdt  \u001b[0m\u001b[1m tg    \u001b[0m\u001b[1m inuidur1 \u001b[0m\u001b[1m inuidur2 \u001b[0m\u001b[1m female \u001b[0m\u001b[1m black \u001b[0m\u001b[1m hispanic \u001b[0m\u001b[1m othrace \u001b[0m\u001b[1m de\u001b[0m ⋯\n",
       "      │\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Int64   \u001b[0m\u001b[90m In\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │ 10824      0        18        18       0      0         0        0     ⋯\n",
       "    2 │ 10824      0         1         1       0      0         0        0\n",
       "    3 │ 10747      0        27        27       0      0         0        0\n",
       "    4 │ 10607      4         9         9       0      0         0        0\n",
       "    5 │ 10831      0        27        27       0      0         0        0     ⋯\n",
       "    6 │ 10845      0        27        27       1      0         0        0\n",
       "    7 │ 10831      0         9         9       1      0         0        0\n",
       "    8 │ 10859      0        27        27       1      0         0        0\n",
       "  ⋮   │   ⋮      ⋮       ⋮         ⋮        ⋮       ⋮       ⋮         ⋮        ⋱\n",
       " 5093 │ 10740      4        13        13       1      1         0        0     ⋯\n",
       " 5094 │ 10845      0         6         6       1      0         0        1\n",
       " 5095 │ 10628      4        10        10       0      0         1        0\n",
       " 5096 │ 10523      4         4         4       0      0         1        0\n",
       " 5097 │ 10558      0         9         9       0      0         0        0     ⋯\n",
       " 5098 │ 10817      4         4         4       0      0         0        0\n",
       " 5099 │ 10691      0        27        27       0      0         0        0\n",
       "\u001b[36m                                                17 columns and 5084 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cleaned[!, :T4] = (df_cleaned.tg .== 4)\n",
    "df_cleaned[!, :y] = log.(Float64.(df_cleaned.inuidur1))\n",
    "df_cleaned.y = replace(df_cleaned.y, -Inf => missing)\n",
    "\n",
    "dropmissing!(df_cleaned, [:y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80efd4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5099-element BitVector:\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " ⋮\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0\n",
       " 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_cleaned[!, :dep_1] = (df_cleaned.dep .== 1)\n",
    "df_cleaned[!, :dep_2] = (df_cleaned.dep .== 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad84d83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17-element Vector{Symbol}:\n",
       " :female\n",
       " :black\n",
       " :othrace\n",
       " :dep_1\n",
       " :dep_2\n",
       " :q2\n",
       " :q3\n",
       " :q4\n",
       " :q5\n",
       " :q6\n",
       " :recall\n",
       " :agelt35\n",
       " :agegt54\n",
       " :durable\n",
       " :nondurable\n",
       " :lusd\n",
       " :husd"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definir lista de features 'x'\n",
    "feature_list = [\n",
    "    :female, :black, :othrace,\n",
    "    :dep_1, :dep_2,  # :dep_0 es referencia\n",
    "    :q2, :q3, :q4, :q5, :q6, # :q1 es referencia\n",
    "    :recall, :agelt35, :agegt54,\n",
    "    :durable, :nondurable, :lusd, :husd\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c81518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5×17 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m female  \u001b[0m\u001b[1m black   \u001b[0m\u001b[1m othrace \u001b[0m\u001b[1m dep_1   \u001b[0m\u001b[1m dep_2   \u001b[0m\u001b[1m q2      \u001b[0m\u001b[1m q3      \u001b[0m\u001b[1m q4      \u001b[0m\u001b[1m q5      \u001b[0m\u001b[1m q6      \u001b[0m\u001b[1m recall  \u001b[0m\u001b[1m agelt35 \u001b[0m\u001b[1m agegt54 \u001b[0m\u001b[1m durable \u001b[0m\u001b[1m nondurable \u001b[0m\u001b[1m lusd    \u001b[0m\u001b[1m husd    \u001b[0m\n",
      "     │\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\n",
      "─────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   1 │     0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0         0.0      0.0      1.0\n",
      "   2 │     0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0         0.0      1.0      0.0\n",
      "   3 │     0.0      0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0      0.0         0.0      1.0      0.0\n",
      "   4 │     0.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0         0.0      0.0      0.0\n",
      "   5 │     0.0      0.0      0.0      1.0      0.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0      1.0      1.0         0.0      1.0      0.0\n"
     ]
    }
   ],
   "source": [
    "# Definir x, y, d\n",
    "x = df_cleaned[!, feature_list]\n",
    "y = df_cleaned.y\n",
    "d = Float64.(df_cleaned.T4) # Convertir Boolean a Float64\n",
    "\n",
    "x = coerce(x, Count => Continuous)\n",
    "println(first(x, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e35c4",
   "metadata": {},
   "source": [
    "## Definición de Funciones DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0af3cdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLJFlux.NeuralNetworkClassifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LinearRegressor = @load LinearRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "LassoCVRegressor = @load LassoCVRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "RandomForestRegressor = @load RandomForestRegressor pkg=MLJScikitLearnInterface verbosity=0\n",
    "NeuralNetworkRegressor = @load NeuralNetworkRegressor pkg=MLJFlux verbosity=0\n",
    "LogisticCVClassifier = @load LogisticCVClassifier pkg=MLJScikitLearnInterface verbosity=0\n",
    "RandomForestClassifier = @load RandomForestClassifier pkg=MLJScikitLearnInterface verbosity=0\n",
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg=MLJFlux verbosity=0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5c852e",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89f0a5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training_sample_append (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function training_sample_append(cv_split, test_sample_index)\n",
    "        training_indices = []\n",
    "        for vector in cv_split[Not(test_sample_index)]\n",
    "                training_indices = [training_indices; vector]\n",
    "        end\n",
    "        return training_indices, cv_split[test_sample_index]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f7e0cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dml (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function dml(x, d, y, modely, modeld, nfold; classifier=true)\n",
    "        n = length(y)\n",
    "        cv = [partition(eachindex(y), fill(1/nfold, nfold-1)..., shuffle = true, rng = 1234)...]\n",
    "        \n",
    "        # Coercionar variables objetivo para MLJ\n",
    "        y_mlj = y\n",
    "        d_mlj = classifier ? categorical(d) : d # d es categórico para clasificadores\n",
    "\n",
    "        machine_y = machine(modely, x, y_mlj, scitype_check_level=0)\n",
    "        machine_d = machine(modeld, x, d_mlj, scitype_check_level=0)\n",
    "        \n",
    "        y_hat = zeros(n)\n",
    "        d_hat = zeros(n)\n",
    "\n",
    "        for fold in 1:nfold\n",
    "                training_fold, test_fold = training_sample_append(cv, fold)\n",
    "                \n",
    "                # Entrenar y predecir Y (Resultado)\n",
    "                MLJ.fit!(machine_y, rows = training_fold)\n",
    "                y_hat[test_fold] = MLJ.predict(machine_y, x[test_fold, :])\n",
    "\n",
    "                # Entrenar y predecir D (Tratamiento)\n",
    "                MLJ.fit!(machine_d, rows = training_fold)\n",
    "                if classifier\n",
    "                    d_hat_probs = MLJ.predict(machine_d, x[test_fold, :])\n",
    "                    # Obtener la probabilidad de la clase '1.0' (equivalente a predict_proba[:, 1])\n",
    "                    d_hat[test_fold] = pdf.(d_hat_probs, 1.0)\n",
    "                else\n",
    "                    d_hat[test_fold] = MLJ.predict(machine_d, x[test_fold, :])\n",
    "                end\n",
    "        end\n",
    "\n",
    "        # Regresión final: resy ~ resd\n",
    "        resy = y .- y_hat\n",
    "        resd = reshape(d .- d_hat, (n, 1))\n",
    "        \n",
    "        ols_data = DataFrame(resy = resy, resd = resd[:, 1])\n",
    "        estimate_model = lm(@formula(resy ~ resd), ols_data)\n",
    "        \n",
    "        # Extraer coeficiente y error estándar para 'resd' (el segundo coeficiente)\n",
    "        coef_est = GLM.coef(estimate_model)[2]\n",
    "        se = GLM.stderror(estimate_model)[2]\n",
    "        \n",
    "        println(\" coef (se) = \", coef_est , \" (\", se, \")\")\n",
    "        return coef_est, se, resy, resd\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "663a8656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dml_naive (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## DML NAIVE\n",
    "function dml_naive(x, d, y, modely, modeld; classifier=true)\n",
    "        n = length(y)\n",
    "        \n",
    "        y_mlj = y\n",
    "        d_mlj = classifier ? categorical(d) : d\n",
    "\n",
    "        # 1. Entrenar modely en TODOS los datos y predecir EN MUESTRA\n",
    "        machine_y = machine(modely, x, y_mlj, scitype_check_level=0)\n",
    "        MLJ.fit!(machine_y, rows = 1:n)\n",
    "        y_hat = MLJ.predict(machine_y, x)\n",
    "\n",
    "        # 2. Entrenar modeld en TODOS los datos y predecir EN MUESTRA\n",
    "        machine_d = machine(modeld, x, d_mlj, scitype_check_level=0)\n",
    "        MLJ.fit!(machine_d, rows = 1:n)\n",
    "        \n",
    "        d_hat = zeros(n)\n",
    "        if classifier\n",
    "            d_hat_probs = MLJ.predict(machine_d, x)\n",
    "            d_hat = pdf.(d_hat_probs, 1.0)\n",
    "        else\n",
    "            d_hat = MLJ.predict(machine_d, x)\n",
    "        end\n",
    "        \n",
    "        # 3. Calcular residuales (en muestra)\n",
    "        resy = y .- y_hat\n",
    "        resd = reshape(d .- d_hat, (n, 1))\n",
    "\n",
    "        # 4. Regresión final\n",
    "        ols_data = DataFrame(resy = resy, resd = resd[:, 1])\n",
    "        estimate_model = lm(@formula(resy ~ resd), ols_data)\n",
    "        \n",
    "        coef_est = GLM.coef(estimate_model)[2]\n",
    "        se = GLM.stderror(estimate_model)[2]\n",
    "        \n",
    "        println(\" coef (se) = \", coef_est , \" (\", se, \")\")\n",
    "        return coef_est, se, resy, resd\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50c1190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summarize (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function summarize(point, stderr, resy, resd, name)\n",
    "        return DataFrame(\n",
    "                model = [name],\n",
    "                estimate = [point], stderr = [stderr], \n",
    "                rmse_y = [sqrt(mean(resy .^ 2))],\n",
    "                # Asegurarse que resd sea un vector para el cálculo de la media\n",
    "                rmse_d = [sqrt(mean(vec(resd) .^ 2))]\n",
    "        )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196310e9",
   "metadata": {},
   "source": [
    "# Debiased ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9abfe",
   "metadata": {},
   "source": [
    "## DEFINIR FUNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bed3a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticPipeline(\n",
       "  standardizer = Standardizer(\n",
       "        features = Symbol[], \n",
       "        ignore = false, \n",
       "        ordered_factor = false, \n",
       "        count = false), \n",
       "  logistic_cv_classifier = LogisticCVClassifier(\n",
       "        Cs = 10, \n",
       "        fit_intercept = true, \n",
       "        cv = 5, \n",
       "        dual = false, \n",
       "        penalty = \"l2\", \n",
       "        scoring = nothing, \n",
       "        solver = \"liblinear\", \n",
       "        tol = 0.0001, \n",
       "        max_iter = 100, \n",
       "        class_weight = nothing, \n",
       "        n_jobs = nothing, \n",
       "        verbose = 0, \n",
       "        refit = true, \n",
       "        intercept_scaling = 1.0, \n",
       "        multi_class = \"auto\", \n",
       "        random_state = 123, \n",
       "        l1_ratios = nothing), \n",
       "  cache = true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. OLS / Logit\n",
    "modely_ols = Standardizer() |> LinearRegressor()\n",
    "modeld_ols = Standardizer() |> LogisticCVClassifier(\n",
    "    cv=5, \n",
    "    random_state=123, \n",
    "    solver=\"liblinear\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3f79503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticPipeline(\n",
       "  standardizer = Standardizer(\n",
       "        features = Symbol[], \n",
       "        ignore = false, \n",
       "        ordered_factor = false, \n",
       "        count = false), \n",
       "  logistic_cv_classifier = LogisticCVClassifier(\n",
       "        Cs = 10, \n",
       "        fit_intercept = true, \n",
       "        cv = 5, \n",
       "        dual = false, \n",
       "        penalty = \"l1\", \n",
       "        scoring = nothing, \n",
       "        solver = \"liblinear\", \n",
       "        tol = 0.0001, \n",
       "        max_iter = 100, \n",
       "        class_weight = nothing, \n",
       "        n_jobs = nothing, \n",
       "        verbose = 0, \n",
       "        refit = true, \n",
       "        intercept_scaling = 1.0, \n",
       "        multi_class = \"auto\", \n",
       "        random_state = 123, \n",
       "        l1_ratios = nothing), \n",
       "  cache = true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Lasso\n",
    "modely_lasso = Standardizer() |> LassoCVRegressor(cv=5, random_state=123)\n",
    "modeld_lasso = Standardizer() |> LogisticCVClassifier(\n",
    "    cv=5, \n",
    "    penalty=\"l1\",      \n",
    "    solver=\"liblinear\",  \n",
    "    random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c36d5dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(\n",
       "  n_estimators = 100, \n",
       "  criterion = \"gini\", \n",
       "  max_depth = nothing, \n",
       "  min_samples_split = 2, \n",
       "  min_samples_leaf = 5, \n",
       "  min_weight_fraction_leaf = 0.0, \n",
       "  max_features = \"sqrt\", \n",
       "  max_leaf_nodes = nothing, \n",
       "  min_impurity_decrease = 0.0, \n",
       "  bootstrap = true, \n",
       "  oob_score = false, \n",
       "  n_jobs = nothing, \n",
       "  random_state = 123, \n",
       "  verbose = 0, \n",
       "  warm_start = false, \n",
       "  class_weight = nothing, \n",
       "  ccp_alpha = 0.0, \n",
       "  max_samples = nothing, \n",
       "  monotonic_cst = nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Random Forest\n",
    "modely_rf = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, random_state=123)\n",
    "modeld_rf = RandomForestClassifier(n_estimators=100, min_samples_leaf=5, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05bb5fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeterministicPipeline(\n",
       "  standardizer = Standardizer(\n",
       "        features = Symbol[], \n",
       "        ignore = false, \n",
       "        ordered_factor = false, \n",
       "        count = false), \n",
       "  neural_network_regressor = NeuralNetworkRegressor(\n",
       "        builder = MLP(hidden = (50, 20), …), \n",
       "        optimiser = Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), \n",
       "        loss = Flux.Losses.mse, \n",
       "        epochs = 100, \n",
       "        batch_size = 32, \n",
       "        lambda = 0.0, \n",
       "        alpha = 0.0, \n",
       "        rng = 123, \n",
       "        optimiser_changes_trigger_retraining = false, \n",
       "        acceleration = CPU1{Nothing}(nothing), \n",
       "        embedding_dims = Dict{Symbol, Real}()), \n",
       "  cache = true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Neural Network (NN)\n",
    "builder_reg = MLJFlux.MLP(hidden=(50, 20), σ=relu)\n",
    "modely_nn = Standardizer() |> NeuralNetworkRegressor(\n",
    "    builder = builder_reg, \n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    optimiser = Flux.ADAM(0.001),\n",
    "    rng = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fadc507e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbabilisticPipeline(\n",
       "  standardizer = Standardizer(\n",
       "        features = Symbol[], \n",
       "        ignore = false, \n",
       "        ordered_factor = false, \n",
       "        count = false), \n",
       "  neural_network_classifier = NeuralNetworkClassifier(\n",
       "        builder = MLP(hidden = (50, 20), …), \n",
       "        finaliser = NNlib.softmax, \n",
       "        optimiser = Adam(eta=0.001, beta=(0.9, 0.999), epsilon=1.0e-8), \n",
       "        loss = Flux.Losses.crossentropy, \n",
       "        epochs = 100, \n",
       "        batch_size = 32, \n",
       "        lambda = 0.0, \n",
       "        alpha = 0.0, \n",
       "        rng = 123, \n",
       "        optimiser_changes_trigger_retraining = false, \n",
       "        acceleration = CPU1{Nothing}(nothing), \n",
       "        embedding_dims = Dict{Symbol, Real}()), \n",
       "  cache = true)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "builder_clf = MLJFlux.MLP(hidden=(50, 20), σ=relu)\n",
    "modeld_nn = Standardizer() |> NeuralNetworkClassifier(\n",
    "    builder = builder_clf, \n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    optimiser = Flux.ADAM(0.001),\n",
    "    rng = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c350aba",
   "metadata": {},
   "source": [
    "## EJECUTAR DML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97c51d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " OLS/Logit \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.06828218690904571 (0.03494935235373572)\n",
      "\n",
      " Lasso \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.06791344479902942 (0.03495011948265716)\n",
      "\n",
      " Random Forest \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.07960873374081812 (0.035415910848292494)\n",
      "\n",
      " NN (MLP) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:27\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:06\u001b[39m\u001b[K\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:01\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:03\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:02\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:04\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.08871607740301986 (0.034779062506370396)\n",
      "┌───────────────┬────────────┬───────────┬─────────┬──────────┐\n",
      "│\u001b[1m         model \u001b[0m│\u001b[1m   estimate \u001b[0m│\u001b[1m    stderr \u001b[0m│\u001b[1m  rmse_y \u001b[0m│\u001b[1m   rmse_d \u001b[0m│\n",
      "│\u001b[90m        String \u001b[0m│\u001b[90m    Float64 \u001b[0m│\u001b[90m   Float64 \u001b[0m│\u001b[90m Float64 \u001b[0m│\u001b[90m  Float64 \u001b[0m│\n",
      "├───────────────┼────────────┼───────────┼─────────┼──────────┤\n",
      "│         Lasso │ -0.0679134 │ 0.0349501 │ 1.19588 │ 0.495465 │\n",
      "│     OLS/Logit │ -0.0682822 │ 0.0349494 │ 1.19593 │ 0.487134 │\n",
      "│ Random Forest │ -0.0796087 │ 0.0354159 │ 1.21201 │ 0.479109 │\n",
      "│      NN (MLP) │ -0.0887161 │ 0.0347791 │ 1.24793 │ 0.502266 │\n",
      "└───────────────┴────────────┴───────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n OLS/Logit \")\n",
    "result_OLS = dml(x, d, y, modely_ols, modeld_ols, 10, classifier=true)\n",
    "table_OLS = summarize(result_OLS..., \"OLS/Logit\")\n",
    "\n",
    "println(\"\\n Lasso \")\n",
    "result_Lasso = dml(x, d, y, modely_lasso, modeld_lasso, 10, classifier=true)\n",
    "table_Lasso = summarize(result_Lasso..., \"Lasso\")\n",
    "\n",
    "println(\"\\n Random Forest \")\n",
    "result_RF = dml(x, d, y, modely_rf, modeld_rf, 10, classifier=true)\n",
    "table_RF = summarize(result_RF..., \"Random Forest\")\n",
    "\n",
    "println(\"\\n NN (MLP) \")\n",
    "result_NN = dml(x, d, y, modely_nn, modeld_nn, 10, classifier=true)\n",
    "table_NN = summarize(result_NN..., \"NN (MLP)\")\n",
    "\n",
    "#  4.3 Combinar y Mostrar Tabla  \n",
    "table_dml = vcat(table_OLS, table_Lasso, table_RF, table_NN)\n",
    "table_dml_sorted = sort(table_dml, [:rmse_y, :rmse_d])\n",
    "\n",
    "pretty_table(table_dml_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ea820",
   "metadata": {},
   "source": [
    "# Debiased ML (sin cross fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c779ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OLS/Logit (Naive) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:linear_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.07231208325663993 (0.035147618160793474)\n",
      "\n",
      "Lasso (Naive) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:lasso_cv_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:logistic_cv_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "C:\\Users\\user2\\.julia\\environments\\v1.12\\.CondaPkg\\.pixi\\envs\\default\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1905: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.07319468093596589 (0.03513484275126338)\n",
      "\n",
      "Random Forest (Naive) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(RandomForestRegressor(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(RandomForestClassifier(n_estimators = 100, …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.07598008605885942 (0.0345611884015284)\n",
      "\n",
      "NN (MLP) (Naive) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training machine(DeterministicPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_regressor, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:03\u001b[39m\u001b[K\n",
      "┌ Info: Training machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:standardizer, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: Training machine(:neural_network_classifier, …).\n",
      "└ @ MLJBase C:\\Users\\user2\\.julia\\packages\\MLJBase\\GY2fM\\src\\machines.jl:499\n",
      "┌ Info: MLJFlux: converting input data to Float32\n",
      "└ @ MLJFlux C:\\Users\\user2\\.julia\\packages\\MLJFlux\\5eWpt\\src\\core.jl:294\n",
      "\u001b[33mOptimising neural net: 100%[=========================] Time: 0:00:04\u001b[39m\u001b[K\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " coef (se) = -0.08518180596029706 (0.03530504421060281)\n",
      "┌───────────────┬────────────┬───────────┬─────────┬──────────┐\n",
      "│\u001b[1m         model \u001b[0m│\u001b[1m   estimate \u001b[0m│\u001b[1m    stderr \u001b[0m│\u001b[1m  rmse_y \u001b[0m│\u001b[1m   rmse_d \u001b[0m│\n",
      "│\u001b[90m        String \u001b[0m│\u001b[90m    Float64 \u001b[0m│\u001b[90m   Float64 \u001b[0m│\u001b[90m Float64 \u001b[0m│\u001b[90m  Float64 \u001b[0m│\n",
      "├───────────────┼────────────┼───────────┼─────────┼──────────┤\n",
      "│      NN (MLP) │ -0.0851818 │  0.035305 │ 1.11211 │ 0.441251 │\n",
      "│ Random Forest │ -0.0759801 │ 0.0345612 │ 1.12841 │ 0.457104 │\n",
      "│     OLS/Logit │ -0.0723121 │ 0.0351476 │ 1.19047 │ 0.494446 │\n",
      "│         Lasso │ -0.0731947 │ 0.0351348 │ 1.19062 │      0.5 │\n",
      "└───────────────┴────────────┴───────────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "println(\"\\nOLS/Logit (Naive) ---\")\n",
    "result_OLS_naive = dml_naive(x, d, y, modely_ols, modeld_ols, classifier=true)\n",
    "table_OLS_naive = summarize(result_OLS_naive..., \"OLS/Logit\")\n",
    "\n",
    "println(\"\\nLasso (Naive) ---\")\n",
    "result_Lasso_naive = dml_naive(x, d, y, modely_lasso, modeld_lasso, classifier=true)\n",
    "table_Lasso_naive = summarize(result_Lasso_naive..., \"Lasso\")\n",
    "\n",
    "println(\"\\nRandom Forest (Naive) ---\")\n",
    "result_RF_naive = dml_naive(x, d, y, modely_rf, modeld_rf, classifier=true)\n",
    "table_RF_naive = summarize(result_RF_naive..., \"Random Forest\")\n",
    "\n",
    "println(\"\\nNN (MLP) (Naive) ---\")\n",
    "result_NN_naive = dml_naive(x, d, y, modely_nn, modeld_nn, classifier=true)\n",
    "table_NN_naive = summarize(result_NN_naive..., \"NN (MLP)\")\n",
    "\n",
    "# Combinar y Mostrar Tabla \n",
    "table_naive = vcat(table_OLS_naive, table_Lasso_naive, table_RF_naive, table_NN_naive)\n",
    "table_naive_sorted = sort(table_naive, [:rmse_y, :rmse_d])\n",
    "\n",
    "pretty_table(table_naive_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6341d07",
   "metadata": {},
   "source": [
    "# comparar tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a254b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────────┬────────────┬───────────┬─────────┬──────────┬──────────────────────┐\n",
      "│\u001b[1m         model \u001b[0m│\u001b[1m   estimate \u001b[0m│\u001b[1m    stderr \u001b[0m│\u001b[1m  rmse_y \u001b[0m│\u001b[1m   rmse_d \u001b[0m│\u001b[1m               Method \u001b[0m│\n",
      "│\u001b[90m        String \u001b[0m│\u001b[90m    Float64 \u001b[0m│\u001b[90m   Float64 \u001b[0m│\u001b[90m Float64 \u001b[0m│\u001b[90m  Float64 \u001b[0m│\u001b[90m               String \u001b[0m│\n",
      "├───────────────┼────────────┼───────────┼─────────┼──────────┼──────────────────────┤\n",
      "│         Lasso │ -0.0679134 │ 0.0349501 │ 1.19588 │ 0.495465 │      DML (Cross-Fit) │\n",
      "│         Lasso │ -0.0731947 │ 0.0351348 │ 1.19062 │      0.5 │ Naive (No Cross-Fit) │\n",
      "│      NN (MLP) │ -0.0887161 │ 0.0347791 │ 1.24793 │ 0.502266 │      DML (Cross-Fit) │\n",
      "│      NN (MLP) │ -0.0851818 │  0.035305 │ 1.11211 │ 0.441251 │ Naive (No Cross-Fit) │\n",
      "│     OLS/Logit │ -0.0682822 │ 0.0349494 │ 1.19593 │ 0.487134 │      DML (Cross-Fit) │\n",
      "│     OLS/Logit │ -0.0723121 │ 0.0351476 │ 1.19047 │ 0.494446 │ Naive (No Cross-Fit) │\n",
      "│ Random Forest │ -0.0796087 │ 0.0354159 │ 1.21201 │ 0.479109 │      DML (Cross-Fit) │\n",
      "│ Random Forest │ -0.0759801 │ 0.0345612 │ 1.12841 │ 0.457104 │ Naive (No Cross-Fit) │\n",
      "└───────────────┴────────────┴───────────┴─────────┴──────────┴──────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "table_dml_copy = copy(table_dml)\n",
    "table_naive_copy = copy(table_naive)\n",
    "\n",
    "table_dml_copy[!, :Method] .= \"DML (Cross-Fit)\"\n",
    "table_naive_copy[!, :Method] .= \"Naive (No Cross-Fit)\"\n",
    "\n",
    "comparison = vcat(table_dml_copy, table_naive_copy)\n",
    "\n",
    "comparison_sorted = sort(comparison, :model)\n",
    "CSV.write(output_path, comparison_sorted)\n",
    "pretty_table(comparison_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a186abd",
   "metadata": {},
   "source": [
    "### Pregunta 1: What can you say about the RMSE for predicting y and d?\n",
    "\n",
    "**Respuesta:** Al ver la tabla final, se ve claramente que los valores de `rmse_y` y `rmse_d` son  más bajos en el método \"Naive\" que en el método \"DML (Cross-Fit)\". Esta diferencia es mucho más pronunciada en los modelos flexibles como Random Forest y NN. Esto es por el overfitting!!\n",
    "\n",
    "### Pregunta 2: Why is it that estimating with one function yields lower RMSE than another?\n",
    "\n",
    "**Respuesta:** Esto se debe al **sobreajuste (overfitting)**.\n",
    "\n",
    "* La función **Naive (`dml_naive`)** entrena y evalúa el modelo en el  misma data. Los modelos complejos (especialmente RF y NN) son muy buenos para \"memorizar\" los datos de entrenamiento, incluido el noise. Esto da como resultado un RMSE artificialmente bajo y excesivamente optimista\n",
    "* La función **DML (`dml`)** usa **cross-fitting (ajuste cruzado)**. Entrena el modelo en una parte de los datos(pliegues) y lo evalúa en una parte que no se ha visto anteriormente. Este RMSE de cross fitting es una medida válida y realista del poder predictivo del modelo en datos nuevos.\n",
    "\n",
    "### Pregunta 3: What problem would we have if we chose to estimate without cross-fitting?\n",
    "\n",
    "**Respuesta:** El problema principal es el **sesgo por sobreajuste (overfitting**.\n",
    "\n",
    "La teoría de DML (Double Machine Learning) requiere que los residuos (`resy` y `resD`) se generen de una manera que sea \"ortogonal\" (estadísticamente independiente) del proceso de estimación. El **cross-fitting** es el mecanismo que nos permite lograr esto.\n",
    "\n",
    "En resumen, **sin cross-fitting, sacrificamos la validez y la inferencia causal correcta por un falso sentido de precisión (de un RMSE más bajo) que proviene del overfitting, pero que de probarlo con data no \"aprendida\" resultara en estimaciones erroneas por overfitting**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.12.0",
   "language": "julia",
   "name": "julia-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
