{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# I. Fitting Data (Python)\nEste notebook resuelve la Parte I del trabajo, simulando los datos y entrenando distintas redes neuronales con `scikit-learn`.\nLas imágenes se guardan con sufijo `_python` para diferenciarlas de las versiones en R y Julia."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de semilla para reproducibilidad\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación de datos\n",
    "n = 300\n",
    "x = np.linspace(0, 2 * np.pi, n)\n",
    "epsilon = np.random.normal(0, 0.1, n)\n",
    "y = np.sin(x) + epsilon\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(x, y, s=15, color='blue', label='Datos simulados')\n",
    "plt.title('Simulación de datos: y = sin(x) + ε')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('simulacion_python.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de redes neuronales con distintas funciones de activación\n",
    "X = x.reshape(-1, 1)\n",
    "y_true = y\n",
    "activations = ['logistic', 'tanh', 'relu']\n",
    "models = {}\n",
    "errors = {}\n",
    "\n",
    "for act in activations:\n",
    "    print(f'Entrenando red con activación: {act}')\n",
    "    model = MLPRegressor(hidden_layer_sizes=(50,50,50), activation=act, solver='adam', max_iter=3000, random_state=42)\n",
    "    model.fit(X, y_true)\n",
    "    models[act] = model\n",
    "    y_pred = model.predict(X)\n",
    "    errors[act] = mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico comparativo de activaciones\n",
    "x_grid = np.linspace(0, 2*np.pi, 500).reshape(-1,1)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y, s=15, color='gray', label='Datos reales')\n",
    "for act in activations:\n",
    "    y_pred = models[act].predict(x_grid)\n",
    "    plt.plot(x_grid, y_pred, label=f'NN ({act})', linewidth=2)\n",
    "plt.title('Ajuste de NNs con diferentes funciones de activación')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacion_activaciones_python.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red neuronal mixta (relu -> tanh -> logistic)\n",
    "m1 = MLPRegressor(hidden_layer_sizes=(50,), activation='relu', solver='adam', max_iter=3000, random_state=42)\n",
    "m1.fit(X, y_true)\n",
    "y_stage1 = m1.predict(X).reshape(-1,1)\n",
    "\n",
    "m2 = MLPRegressor(hidden_layer_sizes=(50,), activation='tanh', solver='adam', max_iter=3000, random_state=42)\n",
    "m2.fit(y_stage1, y_true)\n",
    "y_stage2 = m2.predict(y_stage1).reshape(-1,1)\n",
    "\n",
    "m3 = MLPRegressor(hidden_layer_sizes=(50,), activation='logistic', solver='adam', max_iter=3000, random_state=42)\n",
    "m3.fit(y_stage2, y_true)\n",
    "y_pred_mix = m3.predict(y_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de comparación incluyendo la red mixta\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y, s=15, color='gray', label='Datos reales')\n",
    "for act in activations:\n",
    "    plt.plot(x_grid, models[act].predict(x_grid), label=f'NN ({act})')\n",
    "plt.plot(x, y_pred_mix, '--', color='black', linewidth=2, label='NN (relu-tanh-logistic)')\n",
    "plt.title('Comparación: NNs con distintas funciones de activación')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('red_mixta_python.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del desempeño de cada red (MSE)\n",
    "print('Errores (MSE) obtenidos:')\n",
    "for act, err in errors.items():\n",
    "    print(f'{act}: {err:.5f}')\n",
    "\n",
    "err_mix = mean_squared_error(y_true, y_pred_mix)\n",
    "print(f'relu-tanh-logistic: {err_mix:.5f}')\n",
    "\n",
    "best = min(errors, key=errors.get)\n",
    "print(f'La red con activación \"{best}\" tuvo el mejor ajuste global (menor MSE).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar tabla con los resultados\n",
    "df_errors = pd.DataFrame({\n",
    "    'Activacion': list(errors.keys()) + ['relu-tanh-logistic'],\n",
    "    'MSE': list(errors.values()) + [err_mix]\n",
    "})\n",
    "df_errors.to_csv('resultados_mse_python.csv', index=False)\n",
    "print('Resultados guardados en resultados_mse_python.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
